{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest \n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Give user the option of choosing the country and job type. Will have to string format the link \n",
      "2) Some of the jobs have incomplete links. Will have to concat to make the link complete. Use regex and for loop to check if starts with https.\n",
      "3) Will have to set a time between scrape for each page and then for scraping of each link. Have to set cap at number of total jobs as well. \n",
      "4) Ask the user for the list of skills he want a summary. That way we can expand it to incorporate any job title and skill set. "
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cat 'project notes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import time\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timer():\n",
    "    '''Calculate time it takes for process to complete\n",
    "    \n",
    "    Args:\n",
    "      None\n",
    "      \n",
    "    Yields:\n",
    "       float : the time in minutes for process to run\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    final_time = (end_time - start_time) / 60\n",
    "    \n",
    "    print(\"The time it took to scrape and compile the results was : {:.2f} minutes\".format(final_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome to the skills summariser. Let's get going\n",
      "\n",
      "Enter the job title you want to search for: data scientist\n",
      "Which country would you like to search in (no abbrevations please): united states\n",
      "Enter the skills you want a summary for and make sure you seperate each skill by a space: python sql\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "print('Hello and welcome to the skills summariser. Let\\'s get going')\n",
    "print('')\n",
    "\n",
    "job_title = input('Enter the job title you want to search for: ')\n",
    "country = input('Which country would you like to search in (no abbrevations please): ')\n",
    "skills = input('Enter the skills you want a summary for and make sure you seperate each skill by a space: ')\n",
    "n_jobs = input('How many jobs do you want to look through. The more the jobs the longer the script might take: ')\n",
    "#initial cleaning \n",
    "\n",
    "job_title = job_title.title()\n",
    "country = country.title()\n",
    "skills = skills.lower().split()\n",
    "\n",
    "#'https://www.indeed.com/jobs?q=business+analyst&l=United+States'\n",
    "primary_link = 'https://www.indeed.com/jobs?{0}&l={1}'\n",
    "further_pages_link = 'https://www.indeed.com/jobs?{0}&l={1}&start={3}'\n",
    "\n",
    "with timer():\n",
    "    \n",
    "    job_df = pd.DataFrame(columns = 'Job Title', 'Organization', 'Job Link', 'Skills Summary')\n",
    "    num = 1\n",
    "    start_range = list(range(10,20000,10))\n",
    "    skills_dict = {}\n",
    "    titles = []\n",
    "    orgs = []\n",
    "    clean_links = []\n",
    "    \n",
    "    while df.shape[0] != int(n_jobs):\n",
    "        if num == 1:\n",
    "            link = primary_link.format(job_title,country)\n",
    "            job_links_page = requests.get(link).text\n",
    "            first_page_parser = BeautifulSoup(job_links_page,'html.parser')\n",
    "            scraped_first_page = first_page_parser.body.find_all('div', attrs = {'data-tn-component':'organicJob'})\n",
    "            \n",
    "            for job in scraped_first_page:\n",
    "                title = job.a.text.strip()\n",
    "                titles.append(title)\n",
    "    \n",
    "                org = job.div.span.text.strip()\n",
    "                orgs.append(org)\n",
    "    \n",
    "                link = job.a.get('href')\n",
    "    \n",
    "                if link.startswith('https'):\n",
    "                    clean_links.append(link)\n",
    "                else:\n",
    "                    join_link = \"https://www.indeed.com\"+link\n",
    "                    clean_links.append(join_link)\n",
    "            \n",
    "            job_df['Job Title'] = titles\n",
    "            job_df['Organization'] = orgs\n",
    "            job_df['Job Link'] = clean_links\n",
    "            \n",
    "            for index,link in enumerate(clean_links):\n",
    "                try:\n",
    "                    jd_request = requests.get(link)\n",
    "                    if jd_request == 200:\n",
    "                        jd_cont = jd_request.text\n",
    "                        job_page = BeautifulSoup(jd_cont,'html.parser')\n",
    "                        description = job_page.find('div', class_ = 'jobsearch-jobDescriptionText').text\n",
    "                        description = description.lower()\n",
    "        \n",
    "                        for skill in skills:\n",
    "                            skill = skill.lower()\n",
    "                \n",
    "                            if skill in description:\n",
    "                                if skill in skills_dict:\n",
    "                                    skills_dict[skill] +=1\n",
    "                                else:\n",
    "                                    skills_dict[skill] = 1\n",
    "                        job_df.loc[index,'Skills Summary'] = skills_dict\n",
    "            \n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                    \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
